{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a1b2c3d4",
   "metadata": {},
   "source": [
    "# LangGraph Collaboration Patterns\n",
    "## Content Strategy Decision Engine\n",
    "\n",
    "Previous notebooks showed **hierarchical** patterns where a supervisor delegates work. But what happens when agents need to truly **collaborate** — analyzing the same problem in parallel, debating opposing viewpoints, or voting on decisions?\n",
    "\n",
    "This notebook covers three powerful collaboration patterns:\n",
    "\n",
    "| Pattern | How It Works | Best For |\n",
    "|---------|-------------|----------|\n",
    "| **Map-Reduce** | Fan out to N agents in parallel, then reduce results | Parallel analysis, multi-perspective research |\n",
    "| **Debate** | Agents argue opposing positions in rounds | Decision-making, risk analysis, stress-testing ideas |\n",
    "| **Voting** | Multiple agents cast structured votes | Group decisions, consensus building, prioritization |\n",
    "\n",
    "### The Key API: `Send()`\n",
    "\n",
    "All three patterns use LangGraph's `Send()` API to **fan out** work to multiple agents simultaneously. Instead of routing to one node, `Send()` creates parallel executions — each with its own state payload.\n",
    "\n",
    "```python\n",
    "from langgraph.constants import Send\n",
    "\n",
    "# Instead of routing to one agent:\n",
    "# return \"analyst\"\n",
    "\n",
    "# Fan out to multiple agents simultaneously:\n",
    "return [\n",
    "    Send(\"analyst\", {\"topic\": \"market\", ...}),\n",
    "    Send(\"analyst\", {\"topic\": \"tech\", ...}),\n",
    "    Send(\"analyst\", {\"topic\": \"customer\", ...}),\n",
    "]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2c3d4e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -q langgraph langchain langchain-openai langchain-community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3d4e5f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import getpass\n",
    "import operator\n",
    "from typing import Annotated, TypedDict, Literal, Any\n",
    "\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "from langchain_core.messages import HumanMessage, AIMessage, SystemMessage\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.constants import Send\n",
    "\n",
    "if not os.environ.get(\"OPENAI_API_KEY\"):\n",
    "    os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Enter your OpenAI API key: \")\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "print(\"Setup complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4e5f6a7",
   "metadata": {},
   "source": [
    "---\n",
    "# Part A: Map-Reduce Pattern\n",
    "## Parallel Multi-Perspective Analysis\n",
    "\n",
    "### The Pattern\n",
    "\n",
    "Map-Reduce fans out identical analysis tasks to multiple agents, each with a different **perspective**, then combines all results into a single synthesis.\n",
    "\n",
    "```\n",
    "                    ┌──────────────┐\n",
    "                    │  Dispatcher   │\n",
    "                    └──────┬───────┘\n",
    "                     Send() │ Fan-out\n",
    "              ┌────────────┼────────────┐\n",
    "              ▼            ▼            ▼\n",
    "        ┌──────────┐ ┌──────────┐ ┌──────────┐\n",
    "        │  Market   │ │   Tech   │ │ Customer │\n",
    "        │  Analyst  │ │  Analyst │ │  Analyst │\n",
    "        └────┬─────┘ └────┬─────┘ └────┬─────┘\n",
    "              └────────────┼────────────┘\n",
    "                     Collect │ (operator.add)\n",
    "                    ┌───────▼──────┐\n",
    "                    │   Reducer    │\n",
    "                    └──────────────┘\n",
    "```\n",
    "\n",
    "### Key Mechanism: `operator.add` Reducer\n",
    "\n",
    "When multiple `Send()` calls write to the same list field, the `operator.add` reducer **concatenates** all results. This is how parallel outputs are automatically collected.\n",
    "\n",
    "```python\n",
    "class State(TypedDict):\n",
    "    analyses: Annotated[list, operator.add]  # All analyst outputs merge here\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5f6a7b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# State for individual analyst work\n",
    "class AnalystInput(TypedDict):\n",
    "    topic: str\n",
    "    perspective: str\n",
    "    context: str\n",
    "\n",
    "# Main state that collects all analyses\n",
    "class MapReduceState(TypedDict):\n",
    "    topic: str\n",
    "    analyses: Annotated[list, operator.add]  # Collects outputs from all analysts\n",
    "    final_synthesis: str\n",
    "\n",
    "print(\"Map-Reduce state types defined\")\n",
    "print(f\"  MapReduceState fields: {list(MapReduceState.__annotations__.keys())}\")\n",
    "print(f\"  Note: 'analyses' uses operator.add reducer for automatic collection\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6a7b8c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "PERSPECTIVES = [\n",
    "    {\n",
    "        \"name\": \"Market Strategist\",\n",
    "        \"perspective\": \"market_strategy\",\n",
    "        \"prompt\": \"\"\"You are a Market Strategist. Analyze this opportunity from a market perspective:\n",
    "- Market size and growth trajectory\n",
    "- Competitive dynamics and market gaps\n",
    "- Go-to-market strategy recommendations\n",
    "- Market timing considerations\n",
    "\n",
    "Be specific with data estimates and strategic recommendations. 2-3 paragraphs.\"\"\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Technology Evaluator\", \n",
    "        \"perspective\": \"technology\",\n",
    "        \"prompt\": \"\"\"You are a Technology Evaluator. Analyze this opportunity from a technology perspective:\n",
    "- Technical feasibility and maturity of required technologies\n",
    "- Build vs buy considerations\n",
    "- Technical risks and mitigation strategies\n",
    "- Infrastructure and scalability requirements\n",
    "\n",
    "Be specific with technical assessments. 2-3 paragraphs.\"\"\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Customer Advocate\",\n",
    "        \"perspective\": \"customer\",\n",
    "        \"prompt\": \"\"\"You are a Customer Advocate. Analyze this opportunity from the customer perspective:\n",
    "- Target customer pain points and willingness to pay\n",
    "- User experience and adoption barriers\n",
    "- Customer acquisition and retention strategies\n",
    "- Customer success metrics and feedback loops\n",
    "\n",
    "Be specific with customer insights. 2-3 paragraphs.\"\"\"\n",
    "    },\n",
    "]\n",
    "\n",
    "def dispatcher(state: MapReduceState) -> list:\n",
    "    \"\"\"Fan out analysis to multiple perspective agents using Send().\"\"\"\n",
    "    return [\n",
    "        Send(\"analyst\", {\n",
    "            \"topic\": state[\"topic\"],\n",
    "            \"perspective\": p[\"perspective\"],\n",
    "            \"context\": p[\"prompt\"],\n",
    "        })\n",
    "        for p in PERSPECTIVES\n",
    "    ]\n",
    "\n",
    "print(f\"Dispatcher will fan out to {len(PERSPECTIVES)} analysts: {[p['name'] for p in PERSPECTIVES]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7b8c9d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyst(state: AnalystInput) -> dict:\n",
    "    \"\"\"Individual analyst that processes its assigned perspective.\"\"\"\n",
    "    response = llm.invoke([\n",
    "        SystemMessage(content=state[\"context\"]),\n",
    "        HumanMessage(content=f\"Analyze this opportunity: {state['topic']}\"),\n",
    "    ])\n",
    "    \n",
    "    return {\n",
    "        \"analyses\": [{\n",
    "            \"perspective\": state[\"perspective\"],\n",
    "            \"analysis\": response.content,\n",
    "        }]\n",
    "    }\n",
    "\n",
    "def reducer(state: MapReduceState) -> dict:\n",
    "    \"\"\"Synthesize all analyst perspectives into a unified recommendation.\"\"\"\n",
    "    analyses_text = \"\\n\\n\".join([\n",
    "        f\"### {a['perspective'].replace('_', ' ').title()} Analysis:\\n{a['analysis']}\"\n",
    "        for a in state[\"analyses\"]\n",
    "    ])\n",
    "    \n",
    "    response = llm.invoke([\n",
    "        SystemMessage(content=\"\"\"You are a senior strategy consultant. Synthesize multiple analyst perspectives \n",
    "into a unified strategic recommendation. \n",
    "\n",
    "Your synthesis should:\n",
    "1. Identify areas of agreement across perspectives\n",
    "2. Highlight tensions or trade-offs between perspectives\n",
    "3. Provide a clear, actionable recommendation\n",
    "4. Rate the overall opportunity (Strong Opportunity / Moderate Opportunity / Weak Opportunity / Pass)\n",
    "\n",
    "Be concise but comprehensive. Use specific data points from the analyses.\"\"\"),\n",
    "        HumanMessage(content=f\"Topic: {state['topic']}\\n\\nAnalyst Reports:\\n{analyses_text}\"),\n",
    "    ])\n",
    "    \n",
    "    return {\"final_synthesis\": response.content}\n",
    "\n",
    "print(\"Analyst and reducer nodes defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8c9d0e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "mr_graph = StateGraph(MapReduceState)\n",
    "\n",
    "mr_graph.add_node(\"analyst\", analyst)\n",
    "mr_graph.add_node(\"reducer\", reducer)\n",
    "\n",
    "# Dispatcher uses Send() — it's a conditional edge that returns Send objects\n",
    "mr_graph.add_conditional_edges(START, dispatcher, [\"analyst\"])\n",
    "mr_graph.add_edge(\"analyst\", \"reducer\")\n",
    "mr_graph.add_edge(\"reducer\", END)\n",
    "\n",
    "mr_app = mr_graph.compile()\n",
    "print(\"Map-Reduce graph compiled!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9d0e1f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, Image\n",
    "\n",
    "try:\n",
    "    display(Image(mr_app.get_graph().draw_mermaid_png()))\n",
    "except Exception:\n",
    "    print(mr_app.get_graph().draw_mermaid())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0e1f2a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "mr_result = mr_app.invoke({\n",
    "    \"topic\": \"AI-powered healthcare diagnostics: Building a platform that uses computer vision and NLP to assist radiologists in detecting early-stage cancers from medical imaging, starting with lung CT scans.\",\n",
    "    \"analyses\": [],\n",
    "    \"final_synthesis\": \"\",\n",
    "})\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"MAP-REDUCE: Multi-Perspective Opportunity Analysis\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(f\"\\nPerspectives analyzed: {len(mr_result['analyses'])}\")\n",
    "for analysis in mr_result[\"analyses\"]:\n",
    "    print(f\"\\n{'─' * 60}\")\n",
    "    print(f\"  {analysis['perspective'].replace('_', ' ').upper()}\")\n",
    "    print(f\"{'─' * 60}\")\n",
    "    print(f\"  {analysis['analysis'][:400]}...\")\n",
    "\n",
    "print(f\"\\n{'=' * 60}\")\n",
    "print(\"UNIFIED SYNTHESIS\")\n",
    "print(f\"{'=' * 60}\")\n",
    "print(mr_result[\"final_synthesis\"][:800])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1f2a3b4",
   "metadata": {},
   "source": [
    "---\n",
    "# Part B: Debate Pattern\n",
    "## Structured Argumentation\n",
    "\n",
    "### The Pattern\n",
    "\n",
    "Two agents argue **opposing positions** over multiple rounds, moderated by a judge who decides when the debate has reached a conclusion.\n",
    "\n",
    "```\n",
    "moderator_intro → bull_agent → bear_agent → moderator_eval ─┐\n",
    "                      ▲                                       │\n",
    "                      └──── (another round) ──────────────────┘\n",
    "                                                              │\n",
    "                                              (debate over) ──┤\n",
    "                                                              ▼\n",
    "                                                       final_summary\n",
    "```\n",
    "\n",
    "### Why Debate?\n",
    "\n",
    "- **Stress-tests ideas** — Forces explicit consideration of counterarguments\n",
    "- **Reduces bias** — Each agent is incentivized to find weaknesses in the other's position\n",
    "- **Creates better decisions** — The synthesis of bull/bear cases is richer than a single analysis\n",
    "- **Transparent reasoning** — Decision-makers can see both sides of the argument\n",
    "\n",
    "### Key Mechanism: Multi-Round Loops\n",
    "\n",
    "The moderator evaluates after each round and decides whether to continue or conclude. The `round_number` counter prevents infinite debates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2a3b4c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DebateState(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "    topic: str\n",
    "    round_number: int\n",
    "    max_rounds: int\n",
    "    bull_arguments: Annotated[list, operator.add]\n",
    "    bear_arguments: Annotated[list, operator.add]\n",
    "    debate_status: str  # \"ongoing\" or \"concluded\"\n",
    "    final_verdict: str\n",
    "\n",
    "print(\"DebateState defined with round tracking and argument collection\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3b4c5d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def moderator_intro(state: DebateState) -> dict:\n",
    "    \"\"\"Set up the debate with the topic and rules.\"\"\"\n",
    "    response = llm.invoke([\n",
    "        SystemMessage(content=\"\"\"You are a debate moderator. Introduce the topic and frame the key question.\n",
    "Set up what each side should address. Keep it to 2-3 sentences.\"\"\"),\n",
    "        HumanMessage(content=f\"Debate topic: {state['topic']}\"),\n",
    "    ])\n",
    "    \n",
    "    return {\n",
    "        \"messages\": [AIMessage(content=f\"[Moderator] {response.content}\")],\n",
    "        \"round_number\": 1,\n",
    "        \"debate_status\": \"ongoing\",\n",
    "    }\n",
    "\n",
    "def bull_agent(state: DebateState) -> dict:\n",
    "    \"\"\"Argues the bullish/positive case.\"\"\"\n",
    "    round_num = state.get(\"round_number\", 1)\n",
    "    bear_args = state.get(\"bear_arguments\", [])\n",
    "    \n",
    "    if round_num == 1:\n",
    "        prompt = f\"\"\"You are the BULL (advocate FOR the proposal). This is Round {round_num}.\n",
    "Make your opening argument FOR this proposal. Be specific, cite potential benefits, and make a compelling case.\n",
    "Topic: {state['topic']}\"\"\"\n",
    "    else:\n",
    "        last_bear = bear_args[-1] if bear_args else \"No counter-arguments yet.\"\n",
    "        prompt = f\"\"\"You are the BULL (advocate FOR the proposal). This is Round {round_num}.\n",
    "The BEAR just argued: {last_bear}\n",
    "\n",
    "Counter their arguments and strengthen your case. Address their specific points.\n",
    "Topic: {state['topic']}\"\"\"\n",
    "    \n",
    "    response = llm.invoke([\n",
    "        SystemMessage(content=prompt),\n",
    "        *state[\"messages\"],\n",
    "    ])\n",
    "    \n",
    "    return {\n",
    "        \"messages\": [AIMessage(content=f\"[Bull - Round {round_num}] {response.content}\")],\n",
    "        \"bull_arguments\": [response.content],\n",
    "    }\n",
    "\n",
    "def bear_agent(state: DebateState) -> dict:\n",
    "    \"\"\"Argues the bearish/negative case.\"\"\"\n",
    "    round_num = state.get(\"round_number\", 1)\n",
    "    bull_args = state.get(\"bull_arguments\", [])\n",
    "    last_bull = bull_args[-1] if bull_args else \"No arguments yet.\"\n",
    "    \n",
    "    response = llm.invoke([\n",
    "        SystemMessage(content=f\"\"\"You are the BEAR (advocate AGAINST the proposal). This is Round {round_num}.\n",
    "The BULL just argued: {last_bull}\n",
    "\n",
    "Counter their arguments and make the case AGAINST. Identify risks, costs, and alternatives.\n",
    "Topic: {state['topic']}\"\"\"),\n",
    "        *state[\"messages\"],\n",
    "    ])\n",
    "    \n",
    "    return {\n",
    "        \"messages\": [AIMessage(content=f\"[Bear - Round {round_num}] {response.content}\")],\n",
    "        \"bear_arguments\": [response.content],\n",
    "    }\n",
    "\n",
    "class DebateEvaluation(BaseModel):\n",
    "    \"\"\"Moderator's evaluation of the current debate round.\"\"\"\n",
    "    should_continue: bool = Field(description=\"Whether another round of debate would add value\")\n",
    "    reasoning: str = Field(description=\"Why the debate should continue or end\")\n",
    "    leading_side: Literal[\"bull\", \"bear\", \"balanced\"] = Field(description=\"Which side currently has the stronger argument\")\n",
    "\n",
    "moderator_eval_llm = llm.with_structured_output(DebateEvaluation)\n",
    "\n",
    "def moderator_eval(state: DebateState) -> dict:\n",
    "    \"\"\"Evaluate the debate round and decide whether to continue.\"\"\"\n",
    "    round_num = state.get(\"round_number\", 1)\n",
    "    max_rounds = state.get(\"max_rounds\", 3)\n",
    "    \n",
    "    # Force conclusion if at max rounds\n",
    "    if round_num >= max_rounds:\n",
    "        return {\n",
    "            \"messages\": [AIMessage(content=f\"[Moderator] Maximum rounds ({max_rounds}) reached. Moving to final verdict.\")],\n",
    "            \"debate_status\": \"concluded\",\n",
    "        }\n",
    "    \n",
    "    evaluation = moderator_eval_llm.invoke([\n",
    "        SystemMessage(content=\"\"\"You are a debate moderator. Evaluate the current round:\n",
    "- Are both sides making substantive, non-repetitive arguments?\n",
    "- Have the key issues been thoroughly explored?\n",
    "- Would another round add meaningful new perspectives?\n",
    "\n",
    "If arguments are becoming repetitive or all key points have been made, the debate should conclude.\"\"\"),\n",
    "        *state[\"messages\"],\n",
    "    ])\n",
    "    \n",
    "    status = \"ongoing\" if evaluation.should_continue else \"concluded\"\n",
    "    \n",
    "    return {\n",
    "        \"messages\": [AIMessage(content=f\"[Moderator] Round {round_num} evaluation: {evaluation.reasoning} (Leading: {evaluation.leading_side})\")],\n",
    "        \"debate_status\": status,\n",
    "        \"round_number\": round_num + 1,\n",
    "    }\n",
    "\n",
    "def final_summary(state: DebateState) -> dict:\n",
    "    \"\"\"Synthesize the debate into a final verdict.\"\"\"\n",
    "    bull_args = state.get(\"bull_arguments\", [])\n",
    "    bear_args = state.get(\"bear_arguments\", [])\n",
    "    \n",
    "    response = llm.invoke([\n",
    "        SystemMessage(content=\"\"\"You are the debate moderator delivering the final verdict.\n",
    "\n",
    "Synthesize both sides' arguments into a balanced recommendation:\n",
    "1. Strongest bull arguments\n",
    "2. Strongest bear arguments  \n",
    "3. Key trade-offs\n",
    "4. YOUR VERDICT: Recommend FOR, AGAINST, or CONDITIONAL (with specific conditions)\n",
    "\n",
    "Be decisive — don't just summarize, take a position.\"\"\"),\n",
    "        HumanMessage(content=f\"\"\"Topic: {state['topic']}\n",
    "\n",
    "BULL Arguments (all rounds):\n",
    "{chr(10).join(f'Round {i+1}: {arg[:300]}' for i, arg in enumerate(bull_args))}\n",
    "\n",
    "BEAR Arguments (all rounds):\n",
    "{chr(10).join(f'Round {i+1}: {arg[:300]}' for i, arg in enumerate(bear_args))}\"\"\"),\n",
    "    ])\n",
    "    \n",
    "    return {\n",
    "        \"messages\": [AIMessage(content=f\"[Final Verdict] {response.content}\")],\n",
    "        \"final_verdict\": response.content,\n",
    "    }\n",
    "\n",
    "print(\"Debate nodes defined: moderator_intro, bull_agent, bear_agent, moderator_eval, final_summary\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4c5d6e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def route_debate(state: DebateState) -> str:\n",
    "    \"\"\"Route based on debate status.\"\"\"\n",
    "    if state.get(\"debate_status\") == \"concluded\":\n",
    "        return \"final_summary\"\n",
    "    return \"bull_agent\"\n",
    "\n",
    "debate_graph = StateGraph(DebateState)\n",
    "\n",
    "debate_graph.add_node(\"moderator_intro\", moderator_intro)\n",
    "debate_graph.add_node(\"bull_agent\", bull_agent)\n",
    "debate_graph.add_node(\"bear_agent\", bear_agent)\n",
    "debate_graph.add_node(\"moderator_eval\", moderator_eval)\n",
    "debate_graph.add_node(\"final_summary\", final_summary)\n",
    "\n",
    "debate_graph.add_edge(START, \"moderator_intro\")\n",
    "debate_graph.add_edge(\"moderator_intro\", \"bull_agent\")\n",
    "debate_graph.add_edge(\"bull_agent\", \"bear_agent\")\n",
    "debate_graph.add_edge(\"bear_agent\", \"moderator_eval\")\n",
    "debate_graph.add_conditional_edges(\"moderator_eval\", route_debate, {\n",
    "    \"bull_agent\": \"bull_agent\",\n",
    "    \"final_summary\": \"final_summary\",\n",
    "})\n",
    "debate_graph.add_edge(\"final_summary\", END)\n",
    "\n",
    "debate_app = debate_graph.compile()\n",
    "print(\"Debate graph compiled!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5d6e7f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    display(Image(debate_app.get_graph().draw_mermaid_png()))\n",
    "except Exception:\n",
    "    print(debate_app.get_graph().draw_mermaid())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6e7f8a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "debate_result = debate_app.invoke({\n",
    "    \"messages\": [],\n",
    "    \"topic\": \"Should a Fortune 500 company invest $100M in building its own proprietary foundation model, rather than using existing models from OpenAI, Anthropic, or open-source alternatives?\",\n",
    "    \"round_number\": 0,\n",
    "    \"max_rounds\": 3,\n",
    "    \"bull_arguments\": [],\n",
    "    \"bear_arguments\": [],\n",
    "    \"debate_status\": \"\",\n",
    "    \"final_verdict\": \"\",\n",
    "})\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"DEBATE: Build vs Buy Foundation Models ($100M)\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "for msg in debate_result[\"messages\"]:\n",
    "    if isinstance(msg, AIMessage):\n",
    "        print(f\"\\n{msg.content[:400]}\")\n",
    "        print()\n",
    "\n",
    "print(f\"\\nTotal rounds: {debate_result.get('round_number', 0) - 1}\")\n",
    "print(f\"Bull arguments: {len(debate_result.get('bull_arguments', []))}\")\n",
    "print(f\"Bear arguments: {len(debate_result.get('bear_arguments', []))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7f8a9b0",
   "metadata": {},
   "source": [
    "---\n",
    "# Part C: Voting Pattern\n",
    "## Multi-Stakeholder Decision Making\n",
    "\n",
    "### The Pattern\n",
    "\n",
    "Multiple agents with different **roles and priorities** independently evaluate a proposal and cast structured votes. A tally agent counts votes and announces the decision.\n",
    "\n",
    "```\n",
    "                    ┌───────────────────┐\n",
    "                    │ Proposal Presenter │\n",
    "                    └────────┬──────────┘\n",
    "                       Send() │ Fan-out\n",
    "              ┌──────────────┼──────────────┐\n",
    "              ▼              ▼              ▼\n",
    "        ┌──────────┐  ┌──────────┐  ┌──────────┐\n",
    "        │  Voter   │  │  Voter   │  │  Voter   │\n",
    "        │  (CFO)   │  │  (CTO)   │  │  (CPO)   │\n",
    "        └────┬─────┘  └────┬─────┘  └────┬─────┘\n",
    "              └──────────────┼──────────────┘\n",
    "                       Collect │ (operator.add)\n",
    "                    ┌────────▼─────────┐\n",
    "                    │      Tally       │\n",
    "                    └────────┬─────────┘\n",
    "                    ┌────────▼─────────┐\n",
    "                    │    Announce      │\n",
    "                    └──────────────────┘\n",
    "```\n",
    "\n",
    "### Key Mechanism: Structured Output Votes\n",
    "\n",
    "Each voter returns a Pydantic model with their vote and reasoning. This ensures consistent, parseable results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8a9b0c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Vote(BaseModel):\n",
    "    \"\"\"A structured vote from a stakeholder.\"\"\"\n",
    "    voter_role: str = Field(description=\"The role of the voter\")\n",
    "    vote: Literal[\"APPROVE\", \"REJECT\", \"CONDITIONAL\"] = Field(description=\"The vote\")\n",
    "    confidence: float = Field(description=\"Confidence in this vote, 0.0 to 1.0\", ge=0.0, le=1.0)\n",
    "    reasoning: str = Field(description=\"Detailed reasoning for the vote\")\n",
    "    conditions: str = Field(default=\"\", description=\"Conditions if vote is CONDITIONAL\")\n",
    "\n",
    "class VoterInput(TypedDict):\n",
    "    proposal: str\n",
    "    voter_role: str\n",
    "    voter_prompt: str\n",
    "\n",
    "class VotingState(TypedDict):\n",
    "    proposal: str\n",
    "    votes: Annotated[list, operator.add]  # Collects Vote objects from all voters\n",
    "    tally_result: str\n",
    "    final_decision: str\n",
    "\n",
    "vote_llm = llm.with_structured_output(Vote)\n",
    "\n",
    "print(\"Voting state and Vote model defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9b0c1d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "VOTERS = [\n",
    "    {\n",
    "        \"role\": \"CFO (Chief Financial Officer)\",\n",
    "        \"prompt\": \"\"\"You are the CFO. Evaluate this proposal from a FINANCIAL perspective:\n",
    "- ROI and payback period\n",
    "- Budget impact and opportunity cost\n",
    "- Revenue impact and financial risk\n",
    "- Cash flow implications\n",
    "\n",
    "Vote APPROVE, REJECT, or CONDITIONAL. Be specific about financial thresholds.\"\"\"\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"CTO (Chief Technology Officer)\",\n",
    "        \"prompt\": \"\"\"You are the CTO. Evaluate this proposal from a TECHNOLOGY perspective:\n",
    "- Technical feasibility and complexity\n",
    "- Engineering resource requirements\n",
    "- Technical debt and maintenance burden\n",
    "- Innovation potential and competitive advantage\n",
    "\n",
    "Vote APPROVE, REJECT, or CONDITIONAL. Be specific about technical requirements.\"\"\"\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"CPO (Chief Product Officer)\",\n",
    "        \"prompt\": \"\"\"You are the CPO. Evaluate this proposal from a PRODUCT perspective:\n",
    "- Customer demand and market fit\n",
    "- User experience impact\n",
    "- Product roadmap alignment\n",
    "- Competitive differentiation\n",
    "\n",
    "Vote APPROVE, REJECT, or CONDITIONAL. Be specific about product metrics.\"\"\"\n",
    "    },\n",
    "]\n",
    "\n",
    "def proposal_presenter(state: VotingState) -> list:\n",
    "    \"\"\"Present the proposal to all voters simultaneously using Send().\"\"\"\n",
    "    return [\n",
    "        Send(\"voter\", {\n",
    "            \"proposal\": state[\"proposal\"],\n",
    "            \"voter_role\": v[\"role\"],\n",
    "            \"voter_prompt\": v[\"prompt\"],\n",
    "        })\n",
    "        for v in VOTERS\n",
    "    ]\n",
    "\n",
    "def voter(state: VoterInput) -> dict:\n",
    "    \"\"\"Individual voter casts a structured vote.\"\"\"\n",
    "    vote = vote_llm.invoke([\n",
    "        SystemMessage(content=f\"\"\"{state['voter_prompt']}\n",
    "\n",
    "IMPORTANT: Your voter_role field MUST be exactly: {state['voter_role']}\"\"\"),\n",
    "        HumanMessage(content=f\"Proposal to evaluate:\\n\\n{state['proposal']}\"),\n",
    "    ])\n",
    "    \n",
    "    # Ensure role is set correctly\n",
    "    vote.voter_role = state[\"voter_role\"]\n",
    "    \n",
    "    return {\n",
    "        \"votes\": [vote.model_dump()],\n",
    "    }\n",
    "\n",
    "def tally(state: VotingState) -> dict:\n",
    "    \"\"\"Count votes and determine the outcome.\"\"\"\n",
    "    votes = state.get(\"votes\", [])\n",
    "    \n",
    "    approve_count = sum(1 for v in votes if v[\"vote\"] == \"APPROVE\")\n",
    "    reject_count = sum(1 for v in votes if v[\"vote\"] == \"REJECT\")\n",
    "    conditional_count = sum(1 for v in votes if v[\"vote\"] == \"CONDITIONAL\")\n",
    "    \n",
    "    total = len(votes)\n",
    "    avg_confidence = sum(v[\"confidence\"] for v in votes) / total if total > 0 else 0\n",
    "    \n",
    "    tally_text = f\"\"\"VOTE TALLY:\n",
    "  APPROVE: {approve_count}/{total}\n",
    "  REJECT: {reject_count}/{total}  \n",
    "  CONDITIONAL: {conditional_count}/{total}\n",
    "  Average Confidence: {avg_confidence:.0%}\n",
    "\n",
    "INDIVIDUAL VOTES:\"\"\"\n",
    "    \n",
    "    for v in votes:\n",
    "        tally_text += f\"\\n  {v['voter_role']}: {v['vote']} (confidence: {v['confidence']:.0%})\"\n",
    "        tally_text += f\"\\n    Reasoning: {v['reasoning'][:200]}\"\n",
    "        if v.get(\"conditions\"):\n",
    "            tally_text += f\"\\n    Conditions: {v['conditions'][:150]}\"\n",
    "    \n",
    "    return {\"tally_result\": tally_text}\n",
    "\n",
    "def announce(state: VotingState) -> dict:\n",
    "    \"\"\"Announce the final decision based on votes.\"\"\"\n",
    "    response = llm.invoke([\n",
    "        SystemMessage(content=\"\"\"You are the board secretary announcing the voting results.\n",
    "Based on the vote tally, announce the final decision:\n",
    "- Majority APPROVE → \"APPROVED\"\n",
    "- Majority REJECT → \"REJECTED\"  \n",
    "- Mixed/conditional → \"APPROVED WITH CONDITIONS\" (list the conditions)\n",
    "\n",
    "Be formal and specific. Include the vote count and key conditions.\"\"\"),\n",
    "        HumanMessage(content=f\"Proposal: {state['proposal']}\\n\\n{state['tally_result']}\"),\n",
    "    ])\n",
    "    \n",
    "    return {\"final_decision\": response.content}\n",
    "\n",
    "print(f\"Voting nodes defined with {len(VOTERS)} voters: {[v['role'] for v in VOTERS]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0c1d2e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "voting_graph = StateGraph(VotingState)\n",
    "\n",
    "voting_graph.add_node(\"voter\", voter)\n",
    "voting_graph.add_node(\"tally\", tally)\n",
    "voting_graph.add_node(\"announce\", announce)\n",
    "\n",
    "voting_graph.add_conditional_edges(START, proposal_presenter, [\"voter\"])\n",
    "voting_graph.add_edge(\"voter\", \"tally\")\n",
    "voting_graph.add_edge(\"tally\", \"announce\")\n",
    "voting_graph.add_edge(\"announce\", END)\n",
    "\n",
    "voting_app = voting_graph.compile()\n",
    "print(\"Voting graph compiled!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1d2e3f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    display(Image(voting_app.get_graph().draw_mermaid_png()))\n",
    "except Exception:\n",
    "    print(voting_app.get_graph().draw_mermaid())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2e3f4a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "voting_result = voting_app.invoke({\n",
    "    \"proposal\": \"\"\"PROPOSAL: Pivot from B2B SaaS to B2C Consumer App\n",
    "\n",
    "Our enterprise SaaS product has $5M ARR but growth has slowed to 15% YoY. We propose pivoting \n",
    "to a consumer-facing app targeting individual users.\n",
    "\n",
    "Key details:\n",
    "- Estimated pivot cost: $3M over 12 months\n",
    "- Current B2B team: 30 engineers, 10 sales\n",
    "- Consumer market TAM: 10x larger than our B2B TAM\n",
    "- Would require hiring 15 new consumer-focused engineers\n",
    "- B2B revenue would decline ~40% during transition\n",
    "- Consumer product would be freemium with $9.99/month premium tier\n",
    "- Need 500K MAU to break even on consumer side\n",
    "- Competitors: 3 well-funded startups already in consumer space\"\"\",\n",
    "    \"votes\": [],\n",
    "    \"tally_result\": \"\",\n",
    "    \"final_decision\": \"\",\n",
    "})\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"VOTING: B2B to B2C Pivot Decision\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(f\"\\n{voting_result['tally_result']}\")\n",
    "\n",
    "print(f\"\\n{'=' * 60}\")\n",
    "print(\"FINAL DECISION\")\n",
    "print(f\"{'=' * 60}\")\n",
    "print(voting_result[\"final_decision\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3f4a5b6",
   "metadata": {},
   "source": [
    "## Key Takeaways\n",
    "\n",
    "### Pattern Comparison\n",
    "\n",
    "| Aspect | Map-Reduce | Debate | Voting |\n",
    "|--------|-----------|--------|--------|\n",
    "| Agent interaction | Independent (parallel) | Sequential (adversarial) | Independent (parallel) |\n",
    "| `Send()` usage | Fan-out to analysts | Not needed (sequential) | Fan-out to voters |\n",
    "| Output collection | `operator.add` list | Separate bull/bear lists | `operator.add` list |\n",
    "| Best for | Multi-perspective analysis | Stress-testing decisions | Group consensus |\n",
    "| Rounds | Single pass | Multiple rounds | Single pass |\n",
    "| Structured output | Optional | Optional | Essential (Vote model) |\n",
    "\n",
    "### Key API Summary\n",
    "\n",
    "```python\n",
    "# Send() — fan-out to parallel agents\n",
    "from langgraph.constants import Send\n",
    "\n",
    "def dispatcher(state):\n",
    "    return [Send(\"node_name\", {\"key\": \"value\"}) for item in items]\n",
    "\n",
    "# operator.add — collect parallel results\n",
    "from operator import add\n",
    "class State(TypedDict):\n",
    "    results: Annotated[list, operator.add]  # Auto-concatenates\n",
    "\n",
    "# Structured output — typed agent responses\n",
    "class Vote(BaseModel):\n",
    "    vote: Literal[\"YES\", \"NO\"]\n",
    "    reasoning: str\n",
    "\n",
    "vote_llm = llm.with_structured_output(Vote)\n",
    "```\n",
    "\n",
    "### When to Use Each Pattern\n",
    "\n",
    "- **Map-Reduce**: You need the same type of analysis from different perspectives/data sources\n",
    "- **Debate**: You need to stress-test a decision, especially high-stakes ones with unclear trade-offs\n",
    "- **Voting**: You need multiple stakeholders to weigh in with their domain expertise, and a clear decision mechanism\n",
    "\n",
    "### Combining Patterns\n",
    "\n",
    "These patterns compose well:\n",
    "- **Debate + Voting**: Have agents debate, then have a separate panel vote on the winner\n",
    "- **Map-Reduce + Voting**: Gather parallel analyses, then have each analyst vote on the recommendation\n",
    "- **Hierarchical + Map-Reduce**: Each sub-team uses map-reduce internally\n",
    "\n",
    "### Next Steps\n",
    "- **Custom State Machines** → When you need explicit lifecycle stages with complex branching and retry logic\n",
    "- **Human in the Loop** → When you need human approval at certain decision points"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}