{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a1b2c3d4",
   "metadata": {},
   "source": [
    "# LangGraph Advanced Multi-Agent Supervisor\n",
    "## Customer Support Operations Center\n",
    "\n",
    "In our introductory LangGraph tutorial, we built a basic supervisor that routed between a researcher and writer. That supervisor used simple string matching on LLM output to decide routing—functional but fragile.\n",
    "\n",
    "In this notebook, we level up significantly:\n",
    "\n",
    "| Feature | Basic Supervisor | Advanced Supervisor |\n",
    "|---------|-----------------|-------------------|\n",
    "| Routing | String matching on LLM text | **Structured output** via Pydantic models |\n",
    "| State | Just messages | Messages + **scratchpad** + metadata |\n",
    "| Loop safety | None | **Iteration guards** with configurable limits |\n",
    "| Re-routing | One agent per query | Dynamic **re-routing** based on intermediate results |\n",
    "| Quality | None | **Quality check** node that can send work back |\n",
    "\n",
    "### What We're Building\n",
    "\n",
    "A customer support operations center where:\n",
    "- An **intake classifier** categorizes incoming requests\n",
    "- A **supervisor** routes to specialized agents using structured decisions\n",
    "- **Billing**, **tech support**, and **escalation** agents handle their domains\n",
    "- A **quality check** validates resolution quality and can re-route\n",
    "- A **shared scratchpad** lets agents build on each other's findings\n",
    "- **Iteration guards** prevent infinite loops\n",
    "\n",
    "### Architecture\n",
    "```\n",
    "START → intake_classifier → supervisor → {billing_agent, tech_support_agent, escalation_agent} → quality_check → supervisor → END\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2c3d4e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies (skip if already installed)\n",
    "%pip install -q langgraph langchain langchain-openai langchain-community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3d4e5f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import getpass\n",
    "import operator\n",
    "from typing import Annotated, TypedDict, Literal, Any\n",
    "from datetime import datetime\n",
    "\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "from langchain_core.messages import HumanMessage, AIMessage, SystemMessage\n",
    "from langchain_core.tools import tool\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "# API Key setup\n",
    "if not os.environ.get(\"OPENAI_API_KEY\"):\n",
    "    os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Enter your OpenAI API key: \")\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "print(\"Setup complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4e5f6a7",
   "metadata": {},
   "source": [
    "## 1. Designing Rich State\n",
    "\n",
    "In the basic tutorial, our state was just `messages` and `next`. For a production-grade supervisor, we need much more:\n",
    "\n",
    "- **`scratchpad`** — A shared dictionary where agents can store structured findings for other agents to reference\n",
    "- **`iteration_count`** — Guards against infinite routing loops  \n",
    "- **`customer_sentiment`** — Metadata that influences routing decisions\n",
    "- **`resolution_status`** — Tracks whether the issue is resolved, pending, or escalated\n",
    "\n",
    "### Custom Reducer for Scratchpad\n",
    "\n",
    "The scratchpad uses a **merge reducer** — when an agent returns `{\"scratchpad\": {\"billing_info\": {...}}}`, it merges into the existing scratchpad rather than replacing it. This lets agents incrementally build shared context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5f6a7b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_scratchpad(existing: dict, update: dict) -> dict:\n",
    "    \"\"\"Custom reducer: merge new scratchpad entries into existing ones.\"\"\"\n",
    "    merged = existing.copy()\n",
    "    merged.update(update)\n",
    "    return merged\n",
    "\n",
    "class SupervisorState(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "    next: str\n",
    "    scratchpad: Annotated[dict, merge_scratchpad]\n",
    "    iteration_count: int\n",
    "    customer_sentiment: str\n",
    "    resolution_status: str\n",
    "\n",
    "print(\"SupervisorState defined with custom scratchpad reducer\")\n",
    "print(f\"Fields: {list(SupervisorState.__annotations__.keys())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6a7b8c9",
   "metadata": {},
   "source": [
    "## 2. Structured Supervisor Routing with Pydantic\n",
    "\n",
    "The biggest upgrade from our basic supervisor: instead of parsing free-text LLM output, we use **`with_structured_output()`** to force the LLM to return a Pydantic model.\n",
    "\n",
    "This gives us:\n",
    "- **Type-safe routing** — The `next` field is constrained to valid agent names\n",
    "- **Reasoning transparency** — The LLM must explain its routing decision\n",
    "- **Confidence scoring** — We can use confidence to trigger different behaviors\n",
    "- **Zero parsing errors** — No more `if \"researcher\" in response.lower()` fragility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7b8c9d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RouteDecision(BaseModel):\n",
    "    \"\"\"Structured routing decision from the supervisor.\"\"\"\n",
    "    next: Literal[\"billing_agent\", \"tech_support_agent\", \"escalation_agent\", \"quality_check\", \"FINISH\"] = Field(\n",
    "        description=\"The next agent to route to, or FINISH if the task is complete\"\n",
    "    )\n",
    "    reasoning: str = Field(\n",
    "        description=\"Brief explanation of why this routing decision was made\"\n",
    "    )\n",
    "    confidence: float = Field(\n",
    "        description=\"Confidence in this routing decision from 0.0 to 1.0\",\n",
    "        ge=0.0, le=1.0\n",
    "    )\n",
    "\n",
    "# Create a structured LLM that always returns RouteDecision\n",
    "structured_llm = llm.with_structured_output(RouteDecision)\n",
    "\n",
    "# Quick test\n",
    "test_decision = structured_llm.invoke(\n",
    "    \"A customer is asking about a charge on their credit card. Route this to the right agent.\"\n",
    ")\n",
    "print(f\"Decision: {test_decision}\")\n",
    "print(f\"Next: {test_decision.next}\")\n",
    "print(f\"Reasoning: {test_decision.reasoning}\")\n",
    "print(f\"Confidence: {test_decision.confidence}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8c9d0e1",
   "metadata": {},
   "source": [
    "## 3. Mock Tools for Agent Capabilities\n",
    "\n",
    "Each agent has domain-specific tools. In production, these would connect to real databases and APIs. Here we use mock implementations that return realistic data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9d0e1f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def lookup_billing_info(customer_id: str) -> str:\n",
    "    \"\"\"Look up billing information for a customer.\"\"\"\n",
    "    billing_data = {\n",
    "        \"CUST-001\": \"Plan: Enterprise ($299/mo), Last payment: 2024-01-15, Status: Active, Balance: $0.00\",\n",
    "        \"CUST-002\": \"Plan: Pro ($49/mo), Last payment: 2024-01-10, Status: Active, Balance: $49.00 (overdue)\",\n",
    "        \"CUST-003\": \"Plan: Starter ($19/mo), Last payment: 2023-12-01, Status: Suspended, Balance: $57.00\",\n",
    "    }\n",
    "    return billing_data.get(customer_id, f\"No billing record found for {customer_id}\")\n",
    "\n",
    "@tool\n",
    "def check_payment_status(transaction_id: str) -> str:\n",
    "    \"\"\"Check the status of a specific payment transaction.\"\"\"\n",
    "    transactions = {\n",
    "        \"TXN-1001\": \"Amount: $299.00, Date: 2024-01-15, Status: Completed, Method: Credit Card ending 4242\",\n",
    "        \"TXN-1002\": \"Amount: $49.00, Date: 2024-01-10, Status: Failed, Method: Credit Card ending 1234, Error: Insufficient funds\",\n",
    "        \"TXN-1003\": \"Amount: $19.00, Date: 2023-12-01, Status: Refunded, Method: PayPal\",\n",
    "    }\n",
    "    return transactions.get(transaction_id, f\"Transaction {transaction_id} not found\")\n",
    "\n",
    "@tool\n",
    "def search_knowledge_base(query: str) -> str:\n",
    "    \"\"\"Search the technical knowledge base for solutions.\"\"\"\n",
    "    kb = {\n",
    "        \"login\": \"Common login issues: 1) Clear browser cache, 2) Reset password via /forgot-password, 3) Check if account is locked after 5 failed attempts\",\n",
    "        \"api\": \"API troubleshooting: 1) Verify API key in Settings > API, 2) Check rate limits (100 req/min for Pro, 1000 for Enterprise), 3) Ensure correct base URL: api.example.com/v2\",\n",
    "        \"integration\": \"Integration setup: 1) OAuth2 flow required, 2) Callback URL must be HTTPS, 3) Scopes needed: read, write, admin\",\n",
    "        \"performance\": \"Performance issues: 1) Check system status at status.example.com, 2) Clear local cache, 3) Try incognito mode, 4) Check browser compatibility\",\n",
    "    }\n",
    "    for key, value in kb.items():\n",
    "        if key in query.lower():\n",
    "            return value\n",
    "    return f\"No knowledge base articles found for: {query}\"\n",
    "\n",
    "@tool\n",
    "def get_product_docs(feature: str) -> str:\n",
    "    \"\"\"Retrieve product documentation for a specific feature.\"\"\"\n",
    "    docs = {\n",
    "        \"billing\": \"Billing docs: Invoices generated on 1st of month. Payment methods: Credit card, PayPal, Wire transfer. Refund policy: Full refund within 30 days.\",\n",
    "        \"api\": \"API docs: RESTful API v2. Auth: Bearer token. Rate limits vary by plan. Webhooks available for event notifications.\",\n",
    "        \"dashboard\": \"Dashboard docs: Real-time analytics, custom report builder, data export (CSV/JSON), role-based access control.\",\n",
    "    }\n",
    "    return docs.get(feature.lower(), f\"No documentation found for: {feature}\")\n",
    "\n",
    "@tool\n",
    "def create_ticket(priority: str, category: str, description: str) -> str:\n",
    "    \"\"\"Create an escalation ticket in the ticketing system.\"\"\"\n",
    "    ticket_id = f\"TKT-{datetime.now().strftime('%Y%m%d%H%M%S')}\"\n",
    "    return f\"Ticket created: {ticket_id} | Priority: {priority} | Category: {category} | Description: {description}\"\n",
    "\n",
    "print(\"5 tools defined: lookup_billing_info, check_payment_status, search_knowledge_base, get_product_docs, create_ticket\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0e1f2a3",
   "metadata": {},
   "source": [
    "## 4. Intake Classifier Node\n",
    "\n",
    "The first node in our graph classifies the incoming customer request. This determines the initial routing and sets metadata like sentiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1f2a3b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class IntakeClassification(BaseModel):\n",
    "    \"\"\"Classification of incoming customer request.\"\"\"\n",
    "    category: Literal[\"billing\", \"technical\", \"escalation\", \"general\"] = Field(\n",
    "        description=\"The category of the customer's request\"\n",
    "    )\n",
    "    sentiment: Literal[\"positive\", \"neutral\", \"frustrated\", \"angry\"] = Field(\n",
    "        description=\"The customer's emotional tone\"\n",
    "    )\n",
    "    summary: str = Field(\n",
    "        description=\"One-sentence summary of the customer's issue\"\n",
    "    )\n",
    "\n",
    "intake_llm = llm.with_structured_output(IntakeClassification)\n",
    "\n",
    "def intake_classifier(state: SupervisorState) -> dict:\n",
    "    \"\"\"Classify the incoming customer request.\"\"\"\n",
    "    classification = intake_llm.invoke([\n",
    "        SystemMessage(content=\"\"\"You are a customer support intake classifier. \n",
    "Analyze the customer's message and classify it by category and sentiment.\n",
    "Categories: billing (payments, charges, invoices), technical (bugs, API, integrations), \n",
    "escalation (angry customers, repeated issues, legal threats), general (other).\"\"\"),\n",
    "        *state[\"messages\"]\n",
    "    ])\n",
    "    \n",
    "    # Map category to first agent\n",
    "    category_to_agent = {\n",
    "        \"billing\": \"billing_agent\",\n",
    "        \"technical\": \"tech_support_agent\",\n",
    "        \"escalation\": \"escalation_agent\",\n",
    "        \"general\": \"tech_support_agent\",\n",
    "    }\n",
    "    \n",
    "    return {\n",
    "        \"next\": category_to_agent[classification.category],\n",
    "        \"customer_sentiment\": classification.sentiment,\n",
    "        \"scratchpad\": {\n",
    "            \"intake_classification\": {\n",
    "                \"category\": classification.category,\n",
    "                \"sentiment\": classification.sentiment,\n",
    "                \"summary\": classification.summary,\n",
    "            }\n",
    "        },\n",
    "        \"iteration_count\": 0,\n",
    "        \"resolution_status\": \"in_progress\",\n",
    "    }\n",
    "\n",
    "print(\"Intake classifier defined — classifies by category + sentiment\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2a3b4c5",
   "metadata": {},
   "source": [
    "## 5. The Supervisor Node\n",
    "\n",
    "The supervisor is the brain of our system. It:\n",
    "1. Reviews all messages and scratchpad data\n",
    "2. Makes a **structured routing decision** using `RouteDecision`\n",
    "3. Enforces an **iteration guard** to prevent infinite loops\n",
    "4. Can route to quality check or finish the conversation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3b4c5d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_ITERATIONS = 5\n",
    "\n",
    "SUPERVISOR_PROMPT = \"\"\"You are the supervisor of a customer support operations center.\n",
    "\n",
    "Your team:\n",
    "- billing_agent: Handles payment issues, charges, refunds, account billing\n",
    "- tech_support_agent: Handles technical problems, API issues, integrations, bugs\n",
    "- escalation_agent: Handles angry customers, complex issues requiring human handoff, legal concerns\n",
    "\n",
    "Current scratchpad (shared context from agents):\n",
    "{scratchpad}\n",
    "\n",
    "Current iteration: {iteration} of {max_iterations}\n",
    "Customer sentiment: {sentiment}\n",
    "Resolution status: {resolution_status}\n",
    "\n",
    "Based on the conversation so far, decide the next action:\n",
    "- Route to an agent if more work is needed\n",
    "- Route to \"quality_check\" if an agent has provided a response that should be validated\n",
    "- Route to \"FINISH\" if the customer's issue is fully resolved\n",
    "\n",
    "If we're approaching the iteration limit, prefer wrapping up or escalating.\"\"\"\n",
    "\n",
    "def supervisor_node(state: SupervisorState) -> dict:\n",
    "    \"\"\"Supervisor makes structured routing decisions.\"\"\"\n",
    "    iteration = state.get(\"iteration_count\", 0)\n",
    "    \n",
    "    # Iteration guard\n",
    "    if iteration >= MAX_ITERATIONS:\n",
    "        return {\n",
    "            \"next\": \"FINISH\",\n",
    "            \"messages\": [AIMessage(content=\"[Supervisor] Maximum iterations reached. Wrapping up the conversation.\")],\n",
    "            \"resolution_status\": \"max_iterations_reached\",\n",
    "        }\n",
    "    \n",
    "    prompt = SUPERVISOR_PROMPT.format(\n",
    "        scratchpad=state.get(\"scratchpad\", {}),\n",
    "        iteration=iteration,\n",
    "        max_iterations=MAX_ITERATIONS,\n",
    "        sentiment=state.get(\"customer_sentiment\", \"unknown\"),\n",
    "        resolution_status=state.get(\"resolution_status\", \"unknown\"),\n",
    "    )\n",
    "    \n",
    "    decision = structured_llm.invoke([\n",
    "        SystemMessage(content=prompt),\n",
    "        *state[\"messages\"],\n",
    "    ])\n",
    "    \n",
    "    return {\n",
    "        \"next\": decision.next,\n",
    "        \"iteration_count\": iteration + 1,\n",
    "        \"messages\": [AIMessage(content=f\"[Supervisor] Routing to {decision.next} (confidence: {decision.confidence:.0%}). Reason: {decision.reasoning}\")],\n",
    "        \"scratchpad\": {\"last_routing_decision\": {\n",
    "            \"next\": decision.next,\n",
    "            \"reasoning\": decision.reasoning,\n",
    "            \"confidence\": decision.confidence,\n",
    "            \"iteration\": iteration + 1,\n",
    "        }},\n",
    "    }\n",
    "\n",
    "print(f\"Supervisor node defined with {MAX_ITERATIONS}-iteration guard\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4c5d6e7",
   "metadata": {},
   "source": [
    "## 6. Specialized Agent Nodes\n",
    "\n",
    "Each agent has:\n",
    "- A focused **system prompt** defining its expertise\n",
    "- Access to **domain-specific tools**\n",
    "- The ability to read from and write to the **shared scratchpad**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5d6e7f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Billing Agent\n",
    "billing_tools = [lookup_billing_info, check_payment_status]\n",
    "billing_llm = llm.bind_tools(billing_tools)\n",
    "\n",
    "def billing_agent(state: SupervisorState) -> dict:\n",
    "    \"\"\"Billing specialist agent.\"\"\"\n",
    "    scratchpad = state.get(\"scratchpad\", {})\n",
    "    response = billing_llm.invoke([\n",
    "        SystemMessage(content=f\"\"\"You are a billing support specialist. You help customers with:\n",
    "- Payment issues and failed transactions\n",
    "- Billing inquiries and invoice questions  \n",
    "- Refund requests and credit adjustments\n",
    "- Account plan changes\n",
    "\n",
    "Shared context from other agents: {scratchpad}\n",
    "\n",
    "Use your tools to look up billing information. Provide clear, helpful responses.\n",
    "Always reference specific account details when available.\n",
    "If the issue requires technical support or is beyond billing scope, say so clearly.\"\"\"),\n",
    "        *state[\"messages\"],\n",
    "    ])\n",
    "    \n",
    "    # If the LLM made tool calls, execute them\n",
    "    if response.tool_calls:\n",
    "        from langgraph.prebuilt import ToolNode\n",
    "        tool_node = ToolNode(billing_tools)\n",
    "        tool_results = tool_node.invoke({\"messages\": [response]})\n",
    "        \n",
    "        # Make a follow-up call with tool results\n",
    "        follow_up = llm.invoke([\n",
    "            SystemMessage(content=f\"\"\"You are a billing support specialist. \n",
    "Summarize the billing information you found and provide a helpful response to the customer.\n",
    "Shared context: {scratchpad}\"\"\"),\n",
    "            *state[\"messages\"],\n",
    "            response,\n",
    "            *tool_results[\"messages\"],\n",
    "        ])\n",
    "        \n",
    "        return {\n",
    "            \"messages\": [AIMessage(content=f\"[Billing Agent] {follow_up.content}\")],\n",
    "            \"scratchpad\": {\"billing_findings\": follow_up.content},\n",
    "        }\n",
    "    \n",
    "    return {\n",
    "        \"messages\": [AIMessage(content=f\"[Billing Agent] {response.content}\")],\n",
    "        \"scratchpad\": {\"billing_findings\": response.content},\n",
    "    }\n",
    "\n",
    "# Tech Support Agent\n",
    "tech_tools = [search_knowledge_base, get_product_docs]\n",
    "tech_llm = llm.bind_tools(tech_tools)\n",
    "\n",
    "def tech_support_agent(state: SupervisorState) -> dict:\n",
    "    \"\"\"Technical support specialist agent.\"\"\"\n",
    "    scratchpad = state.get(\"scratchpad\", {})\n",
    "    response = tech_llm.invoke([\n",
    "        SystemMessage(content=f\"\"\"You are a technical support specialist. You help customers with:\n",
    "- Software bugs and error messages\n",
    "- API integration issues  \n",
    "- Performance problems\n",
    "- Feature questions and how-to guidance\n",
    "\n",
    "Shared context from other agents: {scratchpad}\n",
    "\n",
    "Use your tools to search the knowledge base and documentation.\n",
    "Provide step-by-step solutions when possible.\n",
    "If the issue requires billing support or escalation, say so clearly.\"\"\"),\n",
    "        *state[\"messages\"],\n",
    "    ])\n",
    "    \n",
    "    if response.tool_calls:\n",
    "        from langgraph.prebuilt import ToolNode\n",
    "        tool_node = ToolNode(tech_tools)\n",
    "        tool_results = tool_node.invoke({\"messages\": [response]})\n",
    "        \n",
    "        follow_up = llm.invoke([\n",
    "            SystemMessage(content=f\"\"\"You are a technical support specialist.\n",
    "Based on the knowledge base results, provide a clear solution to the customer.\n",
    "Shared context: {scratchpad}\"\"\"),\n",
    "            *state[\"messages\"],\n",
    "            response,\n",
    "            *tool_results[\"messages\"],\n",
    "        ])\n",
    "        \n",
    "        return {\n",
    "            \"messages\": [AIMessage(content=f\"[Tech Support] {follow_up.content}\")],\n",
    "            \"scratchpad\": {\"tech_findings\": follow_up.content},\n",
    "        }\n",
    "    \n",
    "    return {\n",
    "        \"messages\": [AIMessage(content=f\"[Tech Support] {response.content}\")],\n",
    "        \"scratchpad\": {\"tech_findings\": response.content},\n",
    "    }\n",
    "\n",
    "# Escalation Agent\n",
    "escalation_tools = [create_ticket]\n",
    "escalation_llm = llm.bind_tools(escalation_tools)\n",
    "\n",
    "def escalation_agent(state: SupervisorState) -> dict:\n",
    "    \"\"\"Escalation specialist for complex or sensitive issues.\"\"\"\n",
    "    scratchpad = state.get(\"scratchpad\", {})\n",
    "    response = escalation_llm.invoke([\n",
    "        SystemMessage(content=f\"\"\"You are an escalation specialist. You handle:\n",
    "- Angry or frustrated customers needing de-escalation\n",
    "- Complex issues that span multiple departments\n",
    "- Legal or compliance concerns\n",
    "- Issues requiring human manager review\n",
    "\n",
    "Shared context from other agents: {scratchpad}\n",
    "\n",
    "Your approach:\n",
    "1. Acknowledge the customer's frustration\n",
    "2. Summarize what has been tried so far\n",
    "3. Create an escalation ticket if needed\n",
    "4. Provide a clear next-steps timeline\"\"\"),\n",
    "        *state[\"messages\"],\n",
    "    ])\n",
    "    \n",
    "    if response.tool_calls:\n",
    "        from langgraph.prebuilt import ToolNode\n",
    "        tool_node = ToolNode(escalation_tools)\n",
    "        tool_results = tool_node.invoke({\"messages\": [response]})\n",
    "        \n",
    "        follow_up = llm.invoke([\n",
    "            SystemMessage(content=f\"\"\"You are an escalation specialist.\n",
    "A ticket has been created. Inform the customer about the escalation and next steps.\n",
    "Shared context: {scratchpad}\"\"\"),\n",
    "            *state[\"messages\"],\n",
    "            response,\n",
    "            *tool_results[\"messages\"],\n",
    "        ])\n",
    "        \n",
    "        return {\n",
    "            \"messages\": [AIMessage(content=f\"[Escalation] {follow_up.content}\")],\n",
    "            \"scratchpad\": {\"escalation_findings\": follow_up.content},\n",
    "            \"resolution_status\": \"escalated\",\n",
    "        }\n",
    "    \n",
    "    return {\n",
    "        \"messages\": [AIMessage(content=f\"[Escalation] {response.content}\")],\n",
    "        \"scratchpad\": {\"escalation_findings\": response.content},\n",
    "        \"resolution_status\": \"escalated\",\n",
    "    }\n",
    "\n",
    "print(\"3 agent nodes defined: billing_agent, tech_support_agent, escalation_agent\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6e7f8a9",
   "metadata": {},
   "source": [
    "## 7. Quality Check Node\n",
    "\n",
    "The quality check is a unique feature of our advanced supervisor. After an agent responds, this node evaluates whether the response actually resolves the customer's issue. It can:\n",
    "- **Approve** the response and route to FINISH\n",
    "- **Re-route** to a different agent if the response is insufficient\n",
    "- **Request refinement** by sending back to the same agent\n",
    "\n",
    "This creates a feedback loop that dramatically improves response quality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7f8a9b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class QualityAssessment(BaseModel):\n",
    "    \"\"\"Quality assessment of an agent's response.\"\"\"\n",
    "    is_resolved: bool = Field(description=\"Whether the customer's issue appears resolved\")\n",
    "    quality_score: float = Field(description=\"Quality score from 0.0 to 1.0\", ge=0.0, le=1.0)\n",
    "    recommendation: Literal[\"approve\", \"reroute_billing\", \"reroute_tech\", \"reroute_escalation\", \"needs_refinement\"] = Field(\n",
    "        description=\"What to do next with this conversation\"\n",
    "    )\n",
    "    feedback: str = Field(description=\"Specific feedback about the response quality\")\n",
    "\n",
    "quality_llm = llm.with_structured_output(QualityAssessment)\n",
    "\n",
    "def quality_check(state: SupervisorState) -> dict:\n",
    "    \"\"\"Evaluate the quality of the agent's response.\"\"\"\n",
    "    assessment = quality_llm.invoke([\n",
    "        SystemMessage(content=\"\"\"You are a quality assurance reviewer for customer support.\n",
    "        \n",
    "Evaluate the last agent response. Consider:\n",
    "1. Did it directly address the customer's question?\n",
    "2. Was the information accurate and specific?\n",
    "3. Was the tone appropriate for the customer's sentiment?\n",
    "4. Are there any loose ends or unanswered aspects?\n",
    "\n",
    "Recommend:\n",
    "- \"approve\" if the response is good and the issue seems resolved\n",
    "- \"reroute_billing/tech/escalation\" if a different specialist is needed\n",
    "- \"needs_refinement\" if the current agent should try again with more detail\"\"\"),\n",
    "        *state[\"messages\"],\n",
    "    ])\n",
    "    \n",
    "    recommendation_to_next = {\n",
    "        \"approve\": \"FINISH\",\n",
    "        \"reroute_billing\": \"billing_agent\",\n",
    "        \"reroute_tech\": \"tech_support_agent\",\n",
    "        \"reroute_escalation\": \"escalation_agent\",\n",
    "        \"needs_refinement\": state.get(\"next\", \"tech_support_agent\"),  # Back to last agent\n",
    "    }\n",
    "    \n",
    "    next_node = recommendation_to_next[assessment.recommendation]\n",
    "    \n",
    "    return {\n",
    "        \"next\": next_node,\n",
    "        \"messages\": [AIMessage(content=f\"[Quality Check] Score: {assessment.quality_score:.0%} | Action: {assessment.recommendation} | {assessment.feedback}\")],\n",
    "        \"scratchpad\": {\"quality_assessment\": {\n",
    "            \"score\": assessment.quality_score,\n",
    "            \"recommendation\": assessment.recommendation,\n",
    "            \"feedback\": assessment.feedback,\n",
    "        }},\n",
    "        \"resolution_status\": \"resolved\" if assessment.is_resolved else \"in_progress\",\n",
    "    }\n",
    "\n",
    "print(\"Quality check node defined — evaluates and can re-route responses\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8a9b0c1",
   "metadata": {},
   "source": [
    "## 8. Graph Assembly\n",
    "\n",
    "Now we wire everything together. The key routing logic:\n",
    "1. **intake_classifier** always routes to **supervisor**\n",
    "2. **supervisor** routes to an agent, quality_check, or FINISH based on structured output\n",
    "3. **Agent nodes** always route to **quality_check** \n",
    "4. **quality_check** routes back to **supervisor** (which then decides next steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9b0c1d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def route_from_supervisor(state: SupervisorState) -> str:\n",
    "    \"\"\"Route based on supervisor's structured decision.\"\"\"\n",
    "    next_node = state.get(\"next\", \"FINISH\")\n",
    "    if next_node == \"FINISH\":\n",
    "        return END\n",
    "    return next_node\n",
    "\n",
    "def route_from_quality(state: SupervisorState) -> str:\n",
    "    \"\"\"Route based on quality check assessment.\"\"\"\n",
    "    next_node = state.get(\"next\", \"FINISH\")\n",
    "    if next_node == \"FINISH\":\n",
    "        return END\n",
    "    return \"supervisor\"  # Always go back through supervisor for re-routing\n",
    "\n",
    "# Build the graph\n",
    "graph = StateGraph(SupervisorState)\n",
    "\n",
    "# Add all nodes\n",
    "graph.add_node(\"intake_classifier\", intake_classifier)\n",
    "graph.add_node(\"supervisor\", supervisor_node)\n",
    "graph.add_node(\"billing_agent\", billing_agent)\n",
    "graph.add_node(\"tech_support_agent\", tech_support_agent)\n",
    "graph.add_node(\"escalation_agent\", escalation_agent)\n",
    "graph.add_node(\"quality_check\", quality_check)\n",
    "\n",
    "# Entry point\n",
    "graph.add_edge(START, \"intake_classifier\")\n",
    "graph.add_edge(\"intake_classifier\", \"supervisor\")\n",
    "\n",
    "# Supervisor routes to agents or finish\n",
    "graph.add_conditional_edges(\"supervisor\", route_from_supervisor, {\n",
    "    \"billing_agent\": \"billing_agent\",\n",
    "    \"tech_support_agent\": \"tech_support_agent\",\n",
    "    \"escalation_agent\": \"escalation_agent\",\n",
    "    \"quality_check\": \"quality_check\",\n",
    "    END: END,\n",
    "})\n",
    "\n",
    "# All agents route to quality check\n",
    "graph.add_edge(\"billing_agent\", \"quality_check\")\n",
    "graph.add_edge(\"tech_support_agent\", \"quality_check\")\n",
    "graph.add_edge(\"escalation_agent\", \"quality_check\")\n",
    "\n",
    "# Quality check routes back to supervisor or finish\n",
    "graph.add_conditional_edges(\"quality_check\", route_from_quality, {\n",
    "    \"supervisor\": \"supervisor\",\n",
    "    END: END,\n",
    "})\n",
    "\n",
    "# Compile\n",
    "app = graph.compile()\n",
    "print(\"Graph compiled successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0c1d2e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the graph\n",
    "from IPython.display import display, Image\n",
    "\n",
    "try:\n",
    "    display(Image(app.get_graph().draw_mermaid_png()))\n",
    "except Exception:\n",
    "    # Fallback to text representation\n",
    "    print(app.get_graph().draw_mermaid())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1d2e3f4",
   "metadata": {},
   "source": [
    "## 9. Scenario 1: Straightforward Billing Inquiry\n",
    "\n",
    "Let's start with a simple case — a customer asking about their bill. This should flow cleanly through intake → supervisor → billing_agent → quality_check → done."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2e3f4a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = app.invoke({\n",
    "    \"messages\": [HumanMessage(content=\"Hi, I'm customer CUST-002 and my last payment of $49 seems to have failed. Can you check what happened with transaction TXN-1002?\")],\n",
    "    \"scratchpad\": {},\n",
    "    \"iteration_count\": 0,\n",
    "    \"customer_sentiment\": \"\",\n",
    "    \"resolution_status\": \"\",\n",
    "    \"next\": \"\",\n",
    "})\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"SCENARIO 1: Straightforward Billing Inquiry\")\n",
    "print(\"=\" * 80)\n",
    "for msg in result[\"messages\"]:\n",
    "    if isinstance(msg, HumanMessage):\n",
    "        print(f\"\\n{'CUSTOMER':>15}: {msg.content[:200]}\")\n",
    "    elif isinstance(msg, AIMessage):\n",
    "        print(f\"\\n{'AGENT':>15}: {msg.content[:300]}\")\n",
    "print(f\"\\n{'RESOLUTION':>15}: {result.get('resolution_status', 'unknown')}\")\n",
    "print(f\"{'ITERATIONS':>15}: {result.get('iteration_count', 0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3f4a5b6",
   "metadata": {},
   "source": [
    "## 10. Scenario 2: Tech Issue That Needs Escalation\n",
    "\n",
    "This scenario tests **dynamic re-routing**. A technical issue that turns out to be more complex, potentially requiring escalation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4a5b6c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "result2 = app.invoke({\n",
    "    \"messages\": [HumanMessage(content=\"Our entire team of 50 people has been locked out of the platform for 3 hours now. We're losing thousands of dollars. Our API integrations are all failing too. This is completely unacceptable and we need this fixed NOW. Customer ID: CUST-001.\")],\n",
    "    \"scratchpad\": {},\n",
    "    \"iteration_count\": 0,\n",
    "    \"customer_sentiment\": \"\",\n",
    "    \"resolution_status\": \"\",\n",
    "    \"next\": \"\",\n",
    "})\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"SCENARIO 2: Tech Issue Requiring Escalation\")\n",
    "print(\"=\" * 80)\n",
    "for msg in result2[\"messages\"]:\n",
    "    if isinstance(msg, HumanMessage):\n",
    "        print(f\"\\n{'CUSTOMER':>15}: {msg.content[:200]}\")\n",
    "    elif isinstance(msg, AIMessage):\n",
    "        print(f\"\\n{'AGENT':>15}: {msg.content[:300]}\")\n",
    "print(f\"\\n{'RESOLUTION':>15}: {result2.get('resolution_status', 'unknown')}\")\n",
    "print(f\"{'ITERATIONS':>15}: {result2.get('iteration_count', 0)}\")\n",
    "print(f\"{'SENTIMENT':>15}: {result2.get('customer_sentiment', 'unknown')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5b6c7d8",
   "metadata": {},
   "source": [
    "## 11. Scenario 3: Ambiguous Multi-Department Issue\n",
    "\n",
    "The most interesting case — a request that touches both billing AND technical domains, requiring the supervisor to coordinate multiple agents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6c7d8e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "result3 = app.invoke({\n",
    "    \"messages\": [HumanMessage(content=\"I upgraded from Pro to Enterprise last week, but my API rate limits haven't changed — I'm still capped at 100 req/min instead of the 1000 I should have. Also, I was charged $299 but my old $49 charge went through too. Can you sort both issues out? Customer CUST-001, transaction TXN-1001.\")],\n",
    "    \"scratchpad\": {},\n",
    "    \"iteration_count\": 0,\n",
    "    \"customer_sentiment\": \"\",\n",
    "    \"resolution_status\": \"\",\n",
    "    \"next\": \"\",\n",
    "})\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"SCENARIO 3: Multi-Department Issue (Billing + Tech)\")\n",
    "print(\"=\" * 80)\n",
    "for msg in result3[\"messages\"]:\n",
    "    if isinstance(msg, HumanMessage):\n",
    "        print(f\"\\n{'CUSTOMER':>15}: {msg.content[:200]}\")\n",
    "    elif isinstance(msg, AIMessage):\n",
    "        print(f\"\\n{'AGENT':>15}: {msg.content[:300]}\")\n",
    "print(f\"\\n{'RESOLUTION':>15}: {result3.get('resolution_status', 'unknown')}\")\n",
    "print(f\"{'ITERATIONS':>15}: {result3.get('iteration_count', 0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7d8e9f0",
   "metadata": {},
   "source": [
    "## 12. Scratchpad Deep Dive\n",
    "\n",
    "The shared scratchpad is one of the most powerful patterns in this system. Let's examine how agents built on each other's findings across our scenarios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8e9f0a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"SCRATCHPAD ANALYSIS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "for name, result_data in [(\"Scenario 1 (Billing)\", result), \n",
    "                           (\"Scenario 2 (Escalation)\", result2),\n",
    "                           (\"Scenario 3 (Multi-dept)\", result3)]:\n",
    "    print(f\"\\n{'─' * 60}\")\n",
    "    print(f\"  {name}\")\n",
    "    print(f\"{'─' * 60}\")\n",
    "    scratchpad = result_data.get(\"scratchpad\", {})\n",
    "    for key, value in scratchpad.items():\n",
    "        if isinstance(value, dict):\n",
    "            print(f\"\\n  [{key}]\")\n",
    "            for k, v in value.items():\n",
    "                v_str = str(v)[:100] + \"...\" if len(str(v)) > 100 else str(v)\n",
    "                print(f\"    {k}: {v_str}\")\n",
    "        else:\n",
    "            v_str = str(value)[:100] + \"...\" if len(str(value)) > 100 else str(value)\n",
    "            print(f\"\\n  [{key}]: {v_str}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9f0a1b2",
   "metadata": {},
   "source": [
    "## 13. Infinite Loop Prevention Demo\n",
    "\n",
    "What happens when the supervisor and quality check keep bouncing back and forth? Our iteration guard kicks in. Let's demonstrate with a deliberately ambiguous request."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0a1b2c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a version with a very low iteration limit for demo\n",
    "LOW_LIMIT = 3\n",
    "\n",
    "def supervisor_node_low_limit(state: SupervisorState) -> dict:\n",
    "    \"\"\"Supervisor with low iteration limit for demo.\"\"\"\n",
    "    iteration = state.get(\"iteration_count\", 0)\n",
    "    \n",
    "    if iteration >= LOW_LIMIT:\n",
    "        return {\n",
    "            \"next\": \"FINISH\",\n",
    "            \"messages\": [AIMessage(content=f\"[Supervisor] Hit iteration limit ({LOW_LIMIT}). Forcing completion to prevent infinite loop.\")],\n",
    "            \"resolution_status\": \"forced_completion\",\n",
    "        }\n",
    "    \n",
    "    prompt = SUPERVISOR_PROMPT.format(\n",
    "        scratchpad=state.get(\"scratchpad\", {}),\n",
    "        iteration=iteration,\n",
    "        max_iterations=LOW_LIMIT,\n",
    "        sentiment=state.get(\"customer_sentiment\", \"unknown\"),\n",
    "        resolution_status=state.get(\"resolution_status\", \"unknown\"),\n",
    "    )\n",
    "    \n",
    "    decision = structured_llm.invoke([\n",
    "        SystemMessage(content=prompt),\n",
    "        *state[\"messages\"],\n",
    "    ])\n",
    "    \n",
    "    return {\n",
    "        \"next\": decision.next,\n",
    "        \"iteration_count\": iteration + 1,\n",
    "        \"messages\": [AIMessage(content=f\"[Supervisor] Iteration {iteration + 1}/{LOW_LIMIT} → {decision.next}\")],\n",
    "    }\n",
    "\n",
    "# Build a graph with low limit\n",
    "demo_graph = StateGraph(SupervisorState)\n",
    "demo_graph.add_node(\"intake_classifier\", intake_classifier)\n",
    "demo_graph.add_node(\"supervisor\", supervisor_node_low_limit)\n",
    "demo_graph.add_node(\"billing_agent\", billing_agent)\n",
    "demo_graph.add_node(\"tech_support_agent\", tech_support_agent)\n",
    "demo_graph.add_node(\"escalation_agent\", escalation_agent)\n",
    "demo_graph.add_node(\"quality_check\", quality_check)\n",
    "\n",
    "demo_graph.add_edge(START, \"intake_classifier\")\n",
    "demo_graph.add_edge(\"intake_classifier\", \"supervisor\")\n",
    "demo_graph.add_conditional_edges(\"supervisor\", route_from_supervisor, {\n",
    "    \"billing_agent\": \"billing_agent\",\n",
    "    \"tech_support_agent\": \"tech_support_agent\",\n",
    "    \"escalation_agent\": \"escalation_agent\",\n",
    "    \"quality_check\": \"quality_check\",\n",
    "    END: END,\n",
    "})\n",
    "demo_graph.add_edge(\"billing_agent\", \"quality_check\")\n",
    "demo_graph.add_edge(\"tech_support_agent\", \"quality_check\")\n",
    "demo_graph.add_edge(\"escalation_agent\", \"quality_check\")\n",
    "demo_graph.add_conditional_edges(\"quality_check\", route_from_quality, {\n",
    "    \"supervisor\": \"supervisor\",\n",
    "    END: END,\n",
    "})\n",
    "demo_app = demo_graph.compile()\n",
    "\n",
    "result_loop = demo_app.invoke({\n",
    "    \"messages\": [HumanMessage(content=\"I have a vague concern about my account. Something feels off but I can't quite pinpoint it. Maybe billing? Maybe a bug? I'm not really sure what's wrong.\")],\n",
    "    \"scratchpad\": {},\n",
    "    \"iteration_count\": 0,\n",
    "    \"customer_sentiment\": \"\",\n",
    "    \"resolution_status\": \"\",\n",
    "    \"next\": \"\",\n",
    "})\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(f\"LOOP PREVENTION DEMO (limit: {LOW_LIMIT} iterations)\")\n",
    "print(\"=\" * 80)\n",
    "for msg in result_loop[\"messages\"]:\n",
    "    if isinstance(msg, AIMessage):\n",
    "        print(f\"  {msg.content[:200]}\")\n",
    "print(f\"\\nFinal status: {result_loop.get('resolution_status', 'unknown')}\")\n",
    "print(f\"Iterations used: {result_loop.get('iteration_count', 0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1b2c3d5",
   "metadata": {},
   "source": [
    "## 14. Key Takeaways\n",
    "\n",
    "### What We Built\n",
    "A production-grade customer support system with:\n",
    "- **Structured routing** via Pydantic models (no more string parsing)\n",
    "- **Shared scratchpad** for inter-agent communication  \n",
    "- **Quality feedback loops** that improve response quality\n",
    "- **Iteration guards** that prevent runaway execution\n",
    "- **Dynamic re-routing** when initial classification is wrong\n",
    "\n",
    "### Key LangGraph Patterns\n",
    "\n",
    "1. **`with_structured_output()`** — Force LLMs to return typed, validated data structures\n",
    "2. **Custom reducers** — The `merge_scratchpad` function shows how to control state merging behavior\n",
    "3. **Conditional edges with 3+ targets** — Real systems need more than binary routing\n",
    "4. **Loop guards** — Always cap iterations in cyclic graphs\n",
    "5. **Quality check pattern** — A reviewer node that can send work back creates self-improving loops\n",
    "\n",
    "### When to Use This Pattern\n",
    "\n",
    "| Scenario | Use Advanced Supervisor? |\n",
    "|----------|------------------------|\n",
    "| Simple Q&A with 2 agents | No — basic supervisor is fine |\n",
    "| Customer support with 3+ specialists | **Yes** |\n",
    "| Any system needing quality assurance | **Yes** |\n",
    "| Workflows with potential infinite loops | **Yes** — iteration guards are essential |\n",
    "| Systems where agents need shared context | **Yes** — scratchpad pattern |\n",
    "\n",
    "### Next Steps\n",
    "- **Hierarchical Teams** → When your supervisor manages too many agents, split into sub-teams\n",
    "- **Collaboration Patterns** → When agents need to debate, vote, or work in parallel\n",
    "- **Custom State Machines** → When you need explicit lifecycle stages with retry logic"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbformat_minor": 5,
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}